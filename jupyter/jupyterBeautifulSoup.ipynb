{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 웹상의 HTML을 가져오는 방법\n",
    "## urlopen & BeautifulSoup 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<http.client.HTTPResponse object at 0x00000171EFAB2880>\n",
      "\n",
      "\n",
      "<html>\n",
      "<head>\n",
      "<title>A Useful Page</title>\n",
      "</head>\n",
      "<body>\n",
      "<h1>An Interesting Title</h1>\n",
      "<div>\n",
      "Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n",
      "</div>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "[<h1>An Interesting Title</h1>]\n",
      "An Interesting Title\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup as bs\n",
    "html = urlopen(\"http://pythonscraping.com/pages/page1.html\")\n",
    "print(html)\n",
    "print(\"\\n\")\n",
    "\n",
    "htmlBs = bs(html, 'html.parser') # 'html.parser', 'lxml' , 'html5lib' 사용가능\n",
    "print(htmlBs) #전체 출력\n",
    "print(htmlBs.select(\"h1\"))\n",
    "print(htmlBs.select_one(\"h1\").string) # .string 시 안에 내용만 출력 select_one 일때문 사용가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error 404: Not Found\n",
      "사이트를 찾을 수 없습니다.\n"
     ]
    }
   ],
   "source": [
    "# 에러 찾기\n",
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from bs4 import BeautifulSoup as bs\n",
    "try:\n",
    "    html = urlopen(\"http://pythonscraping.com/pages/page1.ht11ml\")\n",
    "except HTTPError as e:\n",
    "    print(e)\n",
    "    print(\"사이트를 찾을 수 없습니다.\")\n",
    "else:\n",
    "    print(html)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    htmlBs = bs(html, 'html.parser') # 'html.parser', 'lxml' , 'html5lib' 사용가능\n",
    "    print(htmlBs) #전체 출력\n",
    "    print(htmlBs.select(\"h1\"))\n",
    "    print(htmlBs.select_one(\"h1\").string) # .string 시 안에 내용만 출력 select_one 일때문 사용가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "내용을 찾지 못했습니다.\n"
     ]
    }
   ],
   "source": [
    "# 함수를 이용하여 조금더 구체적인 예외처리\n",
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "def getTitle(url):\n",
    "    try:\n",
    "        html = urlopen(url)\n",
    "    except HTTPError as e:\n",
    "        return \"HTTPError\"\n",
    "    try:\n",
    "        htmlbs = bs(html.read(), 'html.parser')\n",
    "        title = htmlbs.body.h2\n",
    "    except AttributeError as e:\n",
    "        return None\n",
    "    return title\n",
    "\n",
    "title = getTitle(\"http://pythonscraping.com/pages/page1.html\")\n",
    "if title == None:\n",
    "    print(\"내용을 찾지 못했습니다.\")\n",
    "elif title == \"HTTPError\":\n",
    "    print(\"사이트를 찾지 못했습니다.\")\n",
    "else:\n",
    "    print(title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
